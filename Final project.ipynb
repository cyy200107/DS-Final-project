{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:28.136098Z",
          "iopub.status.busy": "2024-10-17T17:17:28.135603Z",
          "iopub.status.idle": "2024-10-17T17:17:29.508010Z",
          "shell.execute_reply": "2024-10-17T17:17:29.507107Z",
          "shell.execute_reply.started": "2024-10-17T17:17:28.136027Z"
        },
        "trusted": true,
        "id": "wcS-gYtY7vKb"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEYmurOp7vKd"
      },
      "source": [
        "### Data preparation and augmentation after its loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:29.510512Z",
          "iopub.status.busy": "2024-10-17T17:17:29.510093Z",
          "iopub.status.idle": "2024-10-17T17:17:37.432834Z",
          "shell.execute_reply": "2024-10-17T17:17:37.432077Z",
          "shell.execute_reply.started": "2024-10-17T17:17:29.510445Z"
        },
        "trusted": true,
        "id": "frpYgKAo7vKd",
        "outputId": "eccfe216-11c9-40a9-e4a5-04b75d384dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 48 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# constants ....\n",
        "batch_size = 64 # samples per batch\n",
        "num_workers = 48 #number of subprocesses to use for data loading\n",
        "valid_percentage = .20\n",
        "\n",
        "\n",
        "# CifarDataset is a class that construct a dataset out of training images\n",
        "# stored as numpy arrays and its corresponding training labels - also\n",
        "# stored as numpy arrays\n",
        "# This CifarDataset class serves also to provide testing images converted\n",
        "# Tensors in a way that they can be provided via a DataLoader\n",
        "class CifarDataset(Dataset):\n",
        "    def __init__(self, data, target=None, transform=None):\n",
        "        self.data = torch.from_numpy(data)\n",
        "        self.target = target if target is None else torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index] if self.target is not None else \"\"\n",
        "        if self.transform:\n",
        "            x = self.transform(x.numpy())\n",
        "\n",
        "        if self.target is None:\n",
        "            return x\n",
        "        else:\n",
        "            return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# loading the images and training labels\n",
        "test_images  = np.load('/content/test_images.npy')\n",
        "train_images = np.load('/content/train_images.npy')\n",
        "train_labels = pd.read_csv('/content/train_labels.csv')\n",
        "train_labels = pd.Series(train_labels['Category'])\n",
        "\n",
        "# we need to correctly  transpose the numpy arrays, so\n",
        "# they can be converted to PIL images later while they are being\n",
        "# drawn from the data loaders\n",
        "train_images = train_images.transpose([0,2,3,1])\n",
        "test_images = test_images.transpose([0,2,3,1])\n",
        "\n",
        "train_int_labels = np.array([]) # numpy array where the training labels are going to be stored as integer value\n",
        "for x in train_labels:\n",
        "    train_int_labels = np.append(train_int_labels, [classes.index(x)])\n",
        "\n",
        "\n",
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# define transformations for the test images, which means only converting them to\n",
        "# Tensors and normalizing them\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# creating the cifar dataset\n",
        "x_train = CifarDataset(train_images, train_int_labels, transform=transform)\n",
        "x_test  = CifarDataset(test_images, transform=test_transform)\n",
        "\n",
        "# training indices to be used for validation purposes\n",
        "indices = list(range(len(x_train)))\n",
        "# split the training dataset into a -real- training dataset and a validation set\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(len(x_train) * valid_percentage)) # we take 24 percent of the training dataset for validation\n",
        "train_indices, valid_indices = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers - they sample/obtain batches from a list of indices.\n",
        "# batches are built out of random sampled elements\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(x_train, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(x_train, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "# the following test loader is used to load all the test images into the model for their classification\n",
        "test_loader  = torch.utils.data.DataLoader(x_test, batch_size=batch_size, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:37.434532Z",
          "iopub.status.busy": "2024-10-17T17:17:37.434199Z",
          "iopub.status.idle": "2024-10-17T17:17:39.386868Z",
          "shell.execute_reply": "2024-10-17T17:17:39.385815Z",
          "shell.execute_reply.started": "2024-10-17T17:17:37.434479Z"
        },
        "trusted": true,
        "id": "_fFvhkHL7vKe",
        "outputId": "0e65be94-d74c-4881-e851-6a4b936b8a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f07e70e21b94>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# get a batch of training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdataiterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert images to numpy for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def showImage(img):\n",
        "    img = img / 2 + 0.5 # unnormalize the picture\n",
        "    plt.imshow(np.transpose(img, (1,2,0))) # convert from Tensor image\n",
        "\n",
        "\n",
        "\n",
        "# get a batch of training images\n",
        "dataiterator = iter(train_loader)\n",
        "images, labels = dataiterator.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the iamges of the batch\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[])\n",
        "    showImage(images[i])\n",
        "    ax.set_title(classes[labels[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:39.389142Z",
          "iopub.status.busy": "2024-10-17T17:17:39.388808Z",
          "iopub.status.idle": "2024-10-17T17:17:52.095037Z",
          "shell.execute_reply": "2024-10-17T17:17:52.094010Z",
          "shell.execute_reply.started": "2024-10-17T17:17:39.389086Z"
        },
        "trusted": true,
        "id": "UK5tsxnT7vKe"
      },
      "outputs": [],
      "source": [
        "rgb_img = np.squeeze(images[8])\n",
        "channels = ['red channel', 'green channel', 'blue channel']\n",
        "\n",
        "fig = plt.figure(figsize = (36, 36))\n",
        "for idx in np.arange(rgb_img.shape[0]):\n",
        "    ax = fig.add_subplot(1, 3, idx + 1)\n",
        "    img = rgb_img[idx]\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_title(channels[idx])\n",
        "    width, height = img.shape\n",
        "    thresh = img.max()/2.5\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "            ax.annotate(str(val), xy=(y,x),\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center', size=8,\n",
        "                    color='white' if img[x][y]<thresh else 'black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFvLSgRX7vKe"
      },
      "source": [
        "## My DenseNet implementation (DenseNet class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XNhuvdB7vKe"
      },
      "source": [
        "### My DenseNet implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:52.097953Z",
          "iopub.status.busy": "2024-10-17T17:17:52.097632Z",
          "iopub.status.idle": "2024-10-17T17:17:52.145918Z",
          "shell.execute_reply": "2024-10-17T17:17:52.144855Z",
          "shell.execute_reply.started": "2024-10-17T17:17:52.097901Z"
        },
        "trusted": true,
        "id": "rkdSOkaC7vKe"
      },
      "outputs": [],
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, nLayers, tlayer=\"Bottleneck\", k=32, compression_factor=0.5, nClasses=100):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # validate parameters...\n",
        "        nLayers, layer, self.compression_factor = self.__Validate_params(nLayers, tlayer, compression_factor)\n",
        "\n",
        "        # create the main sequentail module\n",
        "        self.densenet = nn.Sequential()\n",
        "\n",
        "        # Before entering the first dense block, a convolution with 16 (or twice the growth rate for DenseNet-BC)\n",
        "        # ouput channels is performed on the input images.\n",
        "        preprocess_outmaps = 2 * k if (layer is self.__Bottleneck and self.compression_factor < 1.) else 16\n",
        "        self.densenet.add_module(\"preprocessInput\", nn.Conv2d(3, preprocess_outmaps, kernel_size=3, stride=1, padding=1, padding_mode='zeros', bias=True))\n",
        "\n",
        "        # create the dense blocks according to the size of the 'nLayers' list\n",
        "        # I define - for clarity/readability reasons - a 'innerChanns' variable whose\n",
        "        # value is initialized to 'preprocess_outmaps'\n",
        "        innerChanns = preprocess_outmaps\n",
        "\n",
        "        for indx in range(len(nLayers) - 1): # we skip here the creation of the last dense block ....\n",
        "\n",
        "            # build a dense block with the number of layers according\n",
        "            # to the index 'indx' of the 'nLayers' list\n",
        "            locals()['DenseBlock_{}'.format(indx)] = nn.Sequential()\n",
        "            for f in range(nLayers[indx]):\n",
        "                locals()['DenseBlock_{}'.format(indx)].add_module('H{}'.format(f), layer(innerChanns, k))\n",
        "                innerChanns += k\n",
        "\n",
        "            # add the just built dense block to the main sequential module (i.e. densenet)\n",
        "            self.densenet.add_module('DN_block{}'.format(indx), locals()['DenseBlock_{}'.format(indx)])\n",
        "\n",
        "            \"\"\" We use (...) transition layers between two contiguous dense blocsk \"\"\"\n",
        "            # add a transition layer right after a dense block - do not forget to explicitly add the compression factor argument!\n",
        "            self.densenet.add_module('TransitionLayer_{}'.format(indx), self.__Transition_layer(innerChanns, self.compression_factor))\n",
        "            # update the number of input feature maps of the next Dense Block\n",
        "            innerChanns = int(innerChanns * self.compression_factor)\n",
        "\n",
        "        # create and add the last dense block. This last dense block was previously left aside because\n",
        "        # after this last dense block comes no transition layer. Instead a global average pooling\n",
        "        # takes place together with a fully connected network performing a softmax classifier.\n",
        "        locals()['DenseBlock_{}'.format(len(nLayers) - 1)] = nn.Sequential()\n",
        "        for f in range( nLayers[len(nLayers) - 1] ):\n",
        "            locals()['DenseBlock_{}'.format(len(nLayers) - 1)].add_module('H{}'.format(f), layer(innerChanns, k))\n",
        "            innerChanns += k\n",
        "        # add the just built dense block to the main sequential module (i.e. densenet)\n",
        "        self.densenet.add_module('DN_block{}'.format(len(nLayers) - 1), locals()['DenseBlock_{}'.format(len(nLayers) - 1)])\n",
        "\n",
        "        \"\"\" At the end of the last dense block, a global average pooling is performed\n",
        "            and then a softmax classifier is attached. \"\"\"\n",
        "        # With adaptive pooling the output can be reduced to any feature map size,\n",
        "        # although in practice it is often choosen size 1, in which case\n",
        "        # it does the same thing as global pooling\n",
        "        # - but first a batch and relu layer (I included this two layers after checking the implementation\n",
        "        # I refer to at the begining of this notebook. I checked the evaluation loss without these layer (first)\n",
        "        # and with these layers (after) and it works best wtih them.\n",
        "        preSoftmax_layer = nn.Sequential(\n",
        "            nn.BatchNorm2d(innerChanns),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveMaxPool2d(1)\n",
        "        )\n",
        "        self.densenet.add_module('preSoftmax_layer', preSoftmax_layer)\n",
        "\n",
        "        # a linear transformation is used here as a Softmax layer.\n",
        "        self.fakeSoftmax = nn.Linear(innerChanns, nClasses, bias=True)\n",
        "\n",
        "        # initialize all weights and biases\n",
        "        self.densenet.apply(self.__InitW_uniCenter)\n",
        "        self.fakeSoftmax.apply(self.__InitW_uniCenter)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.densenet(x)\n",
        "        y = y.view(y.size()[0], -1)\n",
        "        return self.fakeSoftmax(y)\n",
        "\n",
        "\n",
        "    def __InitW_uniCenter(self, m):\n",
        "        \"\"\" General rule for setting the weights in a neural network is to set\n",
        "            them to be close to zero without being too small. A uniform gaussian\n",
        "            distribution centered at zero is used towards this end. \"\"\"\n",
        "        classname = m.__class__.__name__\n",
        "        # for every linear layer in a model ...\n",
        "        if classname.find('Linear') != -1:\n",
        "            # get the number of inputs\n",
        "            n = m.in_features\n",
        "            y = 1. / np.sqrt(n)\n",
        "            m.weight.data.uniform_(-y, y)\n",
        "            m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "    \"\"\" Pooling layers. The concatenation operation used in\n",
        "        Eq. (2) is not viable when the size of feature-maps changes.\n",
        "        However, an essential part of convolutional networks is\n",
        "        down-sampling layers that change the size of feature-maps.\n",
        "        To facilitate down-sampling in our architecture we divide\n",
        "        the network into multiple densely connected dense blocks;\n",
        "        see Figure 2. We refer to layers between blocks as transition\n",
        "        layers, which do convolution and pooling. The transition\n",
        "        layers used in our experiments consist of a batch normalization\n",
        "        layer and an 1 x 1 convolutional layer followed by a\n",
        "        2 x 2 average pooling layer. \"\"\"\n",
        "    class __Transition_layer(nn.Module):\n",
        "        def __init__(self, chann_in, compression_factor=1):\n",
        "            # constructor of the class\n",
        "            super().__init__()\n",
        "            \"\"\" Compression. To further improve model compactness,\n",
        "                we can reduce the number of feature-maps at transition\n",
        "                layers. If a dense block contains m feature-maps, we let\n",
        "                the following transition layer generate [θm] output feature-\n",
        "                maps, where 0 < θ ≤ 1is referred to as the compression fac-\n",
        "                tor.  When θ= 1, the number of feature-maps across transi-\n",
        "                tion layers remains unchanged.  We refer the DenseNet with\n",
        "                θ < 1 as DenseNet-C, and we set θ = 0.5 in our experiment.\n",
        "                When both the bottleneck and transition layers with θ < 1\n",
        "                are used, we refer to our model as DenseNet-BC. \"\"\"\n",
        "            chann_out = int(chann_in * compression_factor)\n",
        "            self.__Transition_layer = nn.Sequential(\n",
        "                nn.BatchNorm2d(chann_in),\n",
        "                nn.Conv2d(\n",
        "                    chann_in, chann_out, kernel_size=1, stride=1, padding=0, bias=True\n",
        "                        ),\n",
        "                nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "\n",
        "\n",
        "        def forward(self,x):\n",
        "            return self.__Transition_layer(x)\n",
        "\n",
        "\n",
        "    \"\"\" Bottleneck layers. Although each layer only produces k\n",
        "        output feature-maps, it typically has many more inputs. It\n",
        "        has been noted in [37, 11] that a 1 x 1 convolution can be introduced\n",
        "        as bottleneck layer before each 3 x 3 convolution\n",
        "        to reduce the number of input feature-maps, and thus to\n",
        "        improve computational efficiency. We find this design especially\n",
        "        effective for DenseNet and we refer to our network\n",
        "        with such a bottleneck layer, i.e., to the BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)\n",
        "        vresion of H_l, as DensNet-B. In our experiments, we let each 1x1\n",
        "        convolution produce 4k feature-maps (where k = Growth rate). \"\"\"\n",
        "    class __Bottleneck(nn.Module):\n",
        "        \"\"\" Bottleneck layer is an exclusive layer\n",
        "            of DenseNet-B - a version of DenseNet. \"\"\"\n",
        "        def __init__(self, chann_in, growth_rate):\n",
        "            # constructor of the class\n",
        "            super().__init__()\n",
        "            self.__Bottleneck = nn.Sequential(\n",
        "                nn.BatchNorm2d(chann_in),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(chann_in, 4 * growth_rate, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "                nn.BatchNorm2d(4 * growth_rate),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1,\n",
        "                        padding_mode='zeros', bias=True)\n",
        "            )\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return torch.cat([x, self.__Bottleneck(x)], 1)\n",
        "\n",
        "\n",
        "    \"\"\" Composite function.Motivated by [12], we define H_l(·)\n",
        "        as  a  composite  function  of  three  consecutive  operations:\n",
        "        batch normalization (BN) [14], followed by a rectified lin-\n",
        "        ear unit (ReLU) [6] and a3×3convolution (Conv). \"\"\"\n",
        "    class __H_layer(nn.Module):\n",
        "        \"\"\" Composite function. This layer is used always when\n",
        "            DenseNet-B is not. \"\"\"\n",
        "        def __init__(self, chann_in, growth_rate):\n",
        "            # constructor of the class\n",
        "            super().__init__()\n",
        "            self.h = nn.Sequential(\n",
        "                nn.BatchNorm2d(chann_in),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(chann_in, growth_rate, kernel_size=3, stride=1, padding=1,\n",
        "                        padding_mode='zeros', bias=True)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            return torch.cat([x, self.h(x)], 1)\n",
        "\n",
        "\n",
        "    def __Validate_params(self, nLayers, tlayer, compression_factor):\n",
        "        # validate the parameters given to the main class creator, to\n",
        "        # ensure a minimum degree of sane functionality\n",
        "\n",
        "        # check for the type of layer to be used....\n",
        "        if tlayer == \"Bottleneck\" or tlayer is None:\n",
        "            layer = DenseNet.__Bottleneck\n",
        "            # save the compression factor value - needed to further build the network\n",
        "            real_compression_factor = compression_factor\n",
        "        elif tlayer == \"H_layer\":\n",
        "            layer = DenseNet.__H_layer\n",
        "            # save the compression factor value - needed to further build the network\n",
        "            if compression_factor < 1:\n",
        "                print(\"Compression factor smaller than 1.0 is exclusive of DenseNet BC.\")\n",
        "                print(\"Compression factor has been set to 1.0\")\n",
        "                real_compression_factor = 1.0\n",
        "            else:\n",
        "                real_compression_factor = compression_factor\n",
        "        else:\n",
        "            print(\"Layer type not supported in DenseNet.\")\n",
        "            print(\"Must be either 'Bottleneck' of 'H_layer'\")\n",
        "            print(\"For mor information, refer to the DenseNet paper:\")\n",
        "            print(\"     https://arxiv.org/abs/1608.06993v5\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        # check that nLayers is either of type int or list\n",
        "        # if nLayer is of type list, check that it is not empty\n",
        "        if isinstance(nLayers, int):\n",
        "            nLayers = [nLayers]\n",
        "        elif isinstance(nLayers, list) and 0 < len(nLayers):\n",
        "            nLayers = nLayers\n",
        "        else:\n",
        "            print(\"nLayer must be an int or a list containing the\")\n",
        "            print(\"number of layers to be created per dense block.\")\n",
        "            print(\"If a list is given as argument, so many dense blocks\")\n",
        "            print(\"will be created as elements on the list.\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        return nLayers, layer, real_compression_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSzbSWjN7vKf"
      },
      "source": [
        "### Model training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:52.148046Z",
          "iopub.status.busy": "2024-10-17T17:17:52.147654Z",
          "iopub.status.idle": "2024-10-17T17:17:52.183553Z",
          "shell.execute_reply": "2024-10-17T17:17:52.182759Z",
          "shell.execute_reply.started": "2024-10-17T17:17:52.147989Z"
        },
        "trusted": true,
        "id": "9J6wqIj17vKf"
      },
      "outputs": [],
      "source": [
        "def TrainModel(model, criterion, optimizer, nEpochs, train_stats, bestModelName = None, lr_update_at_Epoch_perc=0.20, minLr_val_at_Epoch_perc=0.9,\n",
        "               train_loader=train_loader, valid_loader=valid_loader):\n",
        "\n",
        "    valid_loss_min = np.Inf # track chane in validation loss\n",
        "    start_lr_update = True\n",
        "    minimum_lr_val_reached = True\n",
        "\n",
        "    initial_lr = optimizer.defaults['lr']\n",
        "    target_lr = 0.001 # const value.\n",
        "    start_lr_update_at_epoch = int(nEpochs * lr_update_at_Epoch_perc)        # start updating the learning rate at this percentage of the nEpochs\n",
        "    epoch_with_last_lr_update = int(nEpochs * minLr_val_at_Epoch_perc)                  # epoch at which the last learning rate update will be done, reaching its minimum value\n",
        "    minum_Lr_atEpoch_percentage = int(nEpochs * minLr_val_at_Epoch_perc)                # percentage of epochs at which the optimization will reach its minimum learning rate\n",
        "    lr_update_step = (initial_lr - target_lr) / (minum_Lr_atEpoch_percentage - start_lr_update_at_epoch)\n",
        "\n",
        "    # check if CUDA is available\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    if train_on_gpu:\n",
        "        print(\"Training on CUDA!\")\n",
        "        # release the GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        model.cuda()\n",
        "    else:\n",
        "        print(\"CUDA is not available.\")\n",
        "\n",
        "    parallel_model = nn.DataParallel(model)     # Encapsulate the model\n",
        "\n",
        "    for epoch in range(1, nEpochs+1):\n",
        "\n",
        "        if epoch >= start_lr_update_at_epoch and optimizer.defaults['lr'] > 0.001:\n",
        "            if start_lr_update:\n",
        "                print(\"Learning rate starts to be updated towards a value of 0.001\")\n",
        "                start_lr_update = False\n",
        "\n",
        "            optimizer.defaults['lr'] -= lr_update_step\n",
        "            if optimizer.defaults['lr'] < 0.001:\n",
        "                optimizer.defaults['lr'] = 0.001 # in case the learning rate update went a bit below 0.001, we reset it to 0.001\n",
        "                                                 # to avoid an extremly slow optimization\n",
        "                if minimum_lr_val_reached:\n",
        "                    print(\"Minimum value of learning rate rached (i.e. 0.001)\")\n",
        "                    minimum_lr_val_reached = False\n",
        "\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "        train_accuracy = 0\n",
        "        top3_train_accuracy = 0\n",
        "\n",
        "        # start counting the elapsed time\n",
        "        starting_timePoint = time.time()\n",
        "\n",
        "        ## Training the model ##\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass -> compute predicted outputs by passing inputs to the model\n",
        "            output = parallel_model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.mean().backward()\n",
        "            # finally, perform one optimization step (an update of the parameters towards the disminution of error direction)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss +=loss.item()*data.size(0)\n",
        "\n",
        "            # calculating train top-1 accuracy\n",
        "            ps = torch.exp(output)\n",
        "            _, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            # calculating train top-3 accuracy\n",
        "            npTop3_classes = ps.topk(3, dim=1)[1].cpu().numpy()\n",
        "            npTarget = target.cpu().numpy()\n",
        "            top3_train_accuracy += np.mean([1 if npTarget[i] in npTop3_classes[i] else 0 for i in range(0, len(npTarget))])\n",
        "\n",
        "        # check how much time has elapsed\n",
        "        time_elapsed = time.time() - starting_timePoint\n",
        "\n",
        "\n",
        "        validation_accuracy = 0\n",
        "        top3_validation_accuracy = 0\n",
        "        ## Validating the model ##\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # forward pass -> compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss\n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "            # calculating validation top-1 accuracy\n",
        "            ps = torch.exp(output)\n",
        "            _, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == target.view(*top_class.shape)\n",
        "            validation_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            # calculating validation top-3 accuracy\n",
        "            npTop3_classes = ps.topk(3, dim=1)[1].cpu().numpy()\n",
        "            npTarget = target.cpu().numpy()\n",
        "            top3_validation_accuracy += np.mean([1 if npTarget[i] in npTop3_classes[i] else 0 for i in range(0, len(npTarget))])\n",
        "\n",
        "        # calculate average losses\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "\n",
        "        # print training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tIn seconds: {:.4f}'.format(\n",
        "            epoch, train_loss, valid_loss, time_elapsed))\n",
        "\n",
        "        # save model if validation loss has decreased!\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print(\"Validation loss decreased ({:.6f} ---> {:.6f}). Saving model.\".format(valid_loss_min,\n",
        "                                                                                        valid_loss,))\n",
        "            if bestModelName is None:\n",
        "                torch.save(model.state_dict(), 'bestModelTrained.pt')\n",
        "            else:\n",
        "                torch.save(model.state_dict(), '{}.pt'.format(bestModelName))\n",
        "\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "        train_stats = train_stats.append({\n",
        "            'Epoch' : epoch,\n",
        "            'Time per epoch' : time_elapsed,\n",
        "            'Avg time per step' : time_elapsed / len(train_loader.sampler),\n",
        "            'Train loss' : train_loss,\n",
        "            'Train accuracy' : train_accuracy / len(train_loader),\n",
        "            'Train top-3 accuracy' : top3_train_accuracy / len(train_loader),\n",
        "            'Validation loss' : valid_loss,\n",
        "            'Validation accuracy' : validation_accuracy / len(valid_loader),\n",
        "            'Validation top-3 accuracy' : top3_validation_accuracy / len(valid_loader)\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return train_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:17:52.185245Z",
          "iopub.status.busy": "2024-10-17T17:17:52.184937Z",
          "iopub.status.idle": "2024-10-17T17:32:44.063322Z",
          "shell.execute_reply": "2024-10-17T17:32:44.062388Z",
          "shell.execute_reply.started": "2024-10-17T17:17:52.185167Z"
        },
        "trusted": true,
        "id": "pahq5BrF7vKf"
      },
      "outputs": [],
      "source": [
        "modDN = DenseNet([12,18,16], tlayer=\"H_layer\", k=32, nClasses=10)\n",
        "nEpochs = 5\n",
        "# as loss function cross entropy loss will be used\n",
        "crit = nn.CrossEntropyLoss()\n",
        "# and the optimizer ...\n",
        "optimizer = optim.SGD(modDN.parameters(), lr=0.01)\n",
        "\n",
        "# we are collect some characteristic data from the training process\n",
        "# to check some statistics\n",
        "train_stats = pd.DataFrame(columns = ['Epoch', 'Time per epoch', 'Avg time per step',\n",
        "                                      'Train loss', 'Train accuracy', 'Train top-3 accuracy',\n",
        "                                      'Validation loss', 'Validation accuracy', 'Validation top-3 accuracy']\n",
        "                          )\n",
        "\n",
        "train_stats = TrainModel(modDN, crit, optimizer, nEpochs, train_stats, bestModelName='modDN_SGD_trained', lr_update_at_Epoch_perc=0.2, minLr_val_at_Epoch_perc=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04JkRJgA7vKg"
      },
      "source": [
        "### Training & Validation losses and accuracy development over the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:36:29.353489Z",
          "iopub.status.busy": "2024-10-17T17:36:29.353069Z",
          "iopub.status.idle": "2024-10-17T17:36:30.148017Z",
          "shell.execute_reply": "2024-10-17T17:36:30.147123Z",
          "shell.execute_reply.started": "2024-10-17T17:36:29.353425Z"
        },
        "trusted": true,
        "id": "69skBqPb7vKg"
      },
      "outputs": [],
      "source": [
        "# plot the train and validation losses\n",
        "fig1 = plt.figure(figsize=(20,8))\n",
        "ax = plt.axes()\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "x = range(1, len(train_stats['Epoch'].values) + 1)\n",
        "ax.plot(x, train_stats['Train loss'].values, '-r', label='train loss')\n",
        "ax.plot(x, train_stats['Validation loss'].values, '-b', label='validation loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "# plot the train and validation accuracies\n",
        "fig2 = plt.figure(figsize=(20,8))\n",
        "ax = plt.axes()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "x = range(1, len(train_stats['Epoch'].values) + 1)\n",
        "ax.plot(x, train_stats['Train accuracy'].values, '-r', label='training acc')\n",
        "ax.plot(x, train_stats['Validation accuracy'].values, '-b', label='validation acc')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# plot the train and validation top-3 accuracy\n",
        "fig2 = plt.figure(figsize=(20,8))\n",
        "ax = plt.axes()\n",
        "plt.title(\"Top-3 Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Top-3 Accuracy\")\n",
        "\n",
        "x = range(1, len(train_stats['Epoch'].values) + 1)\n",
        "ax.plot(x, train_stats['Train accuracy'].values, '-r', label='top-3 training acc')\n",
        "ax.plot(x, train_stats['Validation top-3 accuracy'].values, '-b', label='top-3 validation acc')\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svMan3GI7vKg"
      },
      "source": [
        "## Testing the best parameters obtained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:32:44.919438Z",
          "iopub.status.busy": "2024-10-17T17:32:44.919031Z",
          "iopub.status.idle": "2024-10-17T17:32:47.472684Z",
          "shell.execute_reply": "2024-10-17T17:32:47.471809Z",
          "shell.execute_reply.started": "2024-10-17T17:32:44.919378Z"
        },
        "trusted": true,
        "id": "yT_4D0dA7vKg"
      },
      "outputs": [],
      "source": [
        "# get a batch of test images\n",
        "dataiterator = iter(test_loader)\n",
        "images = dataiterator.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the iamges of the batch\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[])\n",
        "    showImage(images[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-17T17:32:47.474585Z",
          "iopub.status.busy": "2024-10-17T17:32:47.474246Z",
          "iopub.status.idle": "2024-10-17T17:36:23.172968Z",
          "shell.execute_reply": "2024-10-17T17:36:23.172044Z",
          "shell.execute_reply.started": "2024-10-17T17:32:47.474530Z"
        },
        "trusted": true,
        "id": "7oBU3RIw7vKg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# can we move the tensors to GPU?\n",
        "# I evaluate the availability of cuda here again\n",
        "# so that the user can use only this cell to predict the classes of\n",
        "# the test images - provided there is a .pt file at hand (i.e. the .pt file\n",
        "# containing the trained parameters) and that they are loaded to a similar\n",
        "# DenseNet model as the model such parameters were trained (i.e. same mode architecture)\n",
        "\n",
        "eval_modDN = DenseNet([12,18,16], tlayer=\"H_layer\", k=32, nClasses=10)\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if train_on_gpu:\n",
        "    eval_modDN.cuda()\n",
        "    eval_modDN.load_state_dict(torch.load('modDN_SGD_trained.pt'))\n",
        "else:\n",
        "    eval_modDN.load_state_dict(torch.load('modDN_SGD_trained.pt',map_location=torch.device('cpu')))\n",
        "\n",
        "# release the GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# set the DenseNet model for evaluation only\n",
        "# (i.e. disabling dropouts during the forward pass)\n",
        "eval_modDN.eval()\n",
        "\n",
        "# numpy array to hold all the final predictions\n",
        "# (i.e. the name of the class an image belongs to)\n",
        "final_predictions = np.array([], dtype=str)\n",
        "\n",
        "# draw batches of images from the test loader\n",
        "# until all of them have been drawn\n",
        "for image_batch in test_loader:\n",
        "    if train_on_gpu:\n",
        "                image_batch = image_batch.cuda()\n",
        "    # get predictions of the classes of the iamges\n",
        "    # on this batch\n",
        "    mod_output = eval_modDN(image_batch)\n",
        "    _, batch_pred = torch.max(mod_output, 1)\n",
        "    final_predictions = np.append(final_predictions, [classes[x] for x in batch_pred])\n",
        "\n",
        "# release the GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# prepare the submission of the predictions\n",
        "sub = {'Id':[i for i in range(1, 1+len(x_test))], 'Category':final_predictions}\n",
        "submission = pd.DataFrame(sub, columns=['Id', 'Category'])\n",
        "submission.to_csv('submission.csv', index=True, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-10-17T17:36:23.174892Z",
          "iopub.status.busy": "2024-10-17T17:36:23.174603Z",
          "iopub.status.idle": "2024-10-17T17:36:24.026055Z",
          "shell.execute_reply": "2024-10-17T17:36:24.025294Z",
          "shell.execute_reply.started": "2024-10-17T17:36:23.174849Z"
        },
        "trusted": true,
        "id": "Nqt5X3nB7vKg"
      },
      "outputs": [],
      "source": [
        "# get 20 random indexes\n",
        "indexes = np.random.randint(len(test_loader), size=20)\n",
        "\n",
        "prediction_sample_batch = torch.Tensor()\n",
        "# get a test image corresponding to the random index recently drawn\n",
        "for idx in indexes:\n",
        "    prediction_sample_batch = torch.cat([prediction_sample_batch, x_test[idx].unsqueeze(0)],0)\n",
        "\n",
        "\n",
        "if train_on_gpu:\n",
        "    prediction_sample_batch = prediction_sample_batch.cuda()\n",
        "\n",
        "mod_output = eval_modDN(prediction_sample_batch)\n",
        "_, image_pred = torch.max(mod_output, 1)\n",
        "\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "# get numpy images out of the images batch\n",
        "images = prediction_sample_batch.cpu()\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    showImage(images[idx])\n",
        "    ax.set_title('{}'.format(classes[image_pred[idx]]))"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 50766,
          "sourceId": 95183,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 29908,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}